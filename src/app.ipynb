{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400ea37b",
   "metadata": {},
   "source": [
    "# A Demo with DocumentArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f3bb6",
   "metadata": {},
   "source": [
    "Import DocumentArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c75c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docarray import Document, DocumentArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6704f41f",
   "metadata": {},
   "source": [
    "Some configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81928c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "DATA_PATH = f\"{DATA_DIR}/*.jpg\"\n",
    "MAX_DOCS = 1000\n",
    "QUERY_IMAGE = \"./query.jpg\" # image we'll use to search with\n",
    "PLOT_EMBEDDINGS = False # Really useful but have to manually stop it to progress to next cell\n",
    "\n",
    "# Toy data - If data dir doesn't exist, we'll get data of ~800 fashion images from here\n",
    "TOY_DATA_URL = \"https://github.com/alexcg1/neural-search-notebooks/raw/main/fashion-search/data.zip?raw=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9150888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(DATA_DIR) and not os.path.islink(DATA_DIR):\n",
    "    print(f\"Can't find {DATA_DIR}. Downloading toy dataset\")\n",
    "    !wget \"$TOY_DATA_URL\" -O data.zip\n",
    "    !unzip -q data.zip # Don't print out every darn filename\n",
    "    !rm -f data.zip\n",
    "else:\n",
    "    print(f\"Nothing to download. Using {DATA_DIR} for data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7972c197",
   "metadata": {},
   "source": [
    "Use `.from_files` to quickly load them into a `DocumentArray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5676f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = DocumentArray.from_files(DATA_PATH, size=MAX_DOCS)\n",
    "print(f\"{len(docs)} Documents in DocumentArray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9554d",
   "metadata": {},
   "source": [
    "Preview the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.plot_image_sprites()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7985b2",
   "metadata": {},
   "source": [
    "Convert to tensor, normalize so they're all similar enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(d: Document):\n",
    "    return (d.load_uri_to_image_tensor()  # load\n",
    "             .set_image_tensor_shape((80, 60))  # ensure all images right size (dataset image size _should_ be (80, 60))\n",
    "             .set_image_tensor_normalization()  # normalize color \n",
    "             .set_image_tensor_channel_axis(-1, 0))  # switch color axis for the PyTorch model later\n",
    "    \n",
    "docs.apply(preproc)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d8851",
   "metadata": {},
   "source": [
    "Build the model. With bare ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7399221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0973f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchvision==0.11.2\n",
    "import torchvision\n",
    "model = torchvision.models.resnet50(pretrained=True)  # load ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.embed(model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_EMBEDDINGS:\n",
    "    docs.plot_embeddings(image_sprites=True, image_source=\"uri\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a362dc2",
   "metadata": {},
   "source": [
    "Get the query document and do the same process as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download query doc\n",
    "!wget https://github.com/alexcg1/neural-search-notebooks/raw/main/fashion-search/1_build_basic_search/query.jpg -O query.jpg\n",
    "\n",
    "query_doc = Document(uri=QUERY_IMAGE)\n",
    "query_doc.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a561f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw the one Document into a DocumentArray, since that's what we're matching against\n",
    "query_docs = DocumentArray([query_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply same preprocessing\n",
    "query_docs.apply(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ad96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and create embedding just like we did with the dataset\n",
    "query_docs.embed(model, device=device) # If running on non-gpu machine, change \"cuda\" to \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceeaa55",
   "metadata": {},
   "source": [
    "Do the MATCH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e4d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_docs.match(docs, limit=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ee504",
   "metadata": {},
   "outputs": [],
   "source": [
    "(DocumentArray(query_doc.matches, copy=True)\n",
    "    .apply(lambda d: d.set_image_tensor_channel_axis(0, -1)\n",
    "                      .set_image_tensor_inv_normalization())\n",
    "    ).plot_image_sprites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ac4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_EMBEDDINGS:\n",
    "    query_doc.matches.plot_embeddings(image_sprites=True, image_source=\"uri\")\n",
    "query_doc.matches.plot_embeddings(image_sprites=True, image_source=\"uri\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "41fe583a65f337012a64cdee1571837758392d29b56d216e8787b19381c0943e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
